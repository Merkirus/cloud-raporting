# Raportowanie i analiza wydajnoÅ›ci â€“ README

Ten moduÅ‚ odpowiada za **zbieranie danych testowych (RAW)**, ich **agregacjÄ™** oraz **generowanie raportu PDF**. MoÅ¼e dziaÅ‚aÄ‡ zarÃ³wno lokalnie (testowo), jak i jako worker podÅ‚Ä…czony do reszty systemu przez RabbitMQ.

---

## ğŸ“ Struktura projektu

```
aggregates.py
main.py
rabbit_worker.py
report.pdf
repo.py
report_pdf.py
requirements.txt
sample_request_results.json
schema.sql
storage.py
```

---

## ğŸ§  OdpowiedzialnoÅ›ci plikÃ³w

### `main.py`
- Lokalny **test endâ€‘toâ€‘end** bez RabbitMQ.
- Inicjalizuje bazÄ™ danych (`init_db`).
- Wczytuje przykÅ‚adowe dane z `sample_request_results.json`.
- Zapisuje RAW do bazy.
- Liczy agregaty (`compute_aggregates`).
- Odczytuje dane przez `ReportRepository`.
- (Opcjonalnie) generuje PDF.

UÅ¼ywany wyÅ‚Ä…cznie do testÃ³w i debugowania pipelineâ€™u.

---

### `storage.py`
- Warstwa zapisu danych RAW.
- `init_db(db_path, schema.sql)` â€“ tworzy tabele i indeksy.
- `insert_raw_result(db_path, dto)` â€“ zapisuje **jeden** event requestu do bazy.

Nie zawiera logiki agregacji ani raportowania.

---

### `schema.sql`
- Definicja struktury bazy SQLite:
  - `request_results` â€“ surowe dane (RAW)
  - `job_summary` â€“ agregaty globalne per job
  - `endpoint_summary` â€“ agregaty per endpoint + metoda
  - `timeseries_summary` â€“ agregaty czasowe (bucketed)
- Indeksy pod szybkie zapytania raportowe.

---

### `aggregates.py`
- Logika **agregacji danych**.
- `compute_aggregates(db_path, job_id, bucket_seconds)`:
  - czyta RAW z `request_results`
  - liczy metryki (avg, p50, p90, p95, p99, max)
  - zapisuje wyniki do tabel `*_summary` (UPSERT)
- `bucket_seconds` okreÅ›la rozdzielczoÅ›Ä‡ analizy czasowej.

---

### `repo.py`
- Readâ€‘only warstwa dostÄ™pu do danych przygotowanych pod raport.
- `ReportRepository`:
  - `get_job_summary(job_id)`
  - `get_endpoint_summary(job_id)`
  - `get_timeseries_overall(job_id, bucket_seconds)`

Generator PDF korzysta wyÅ‚Ä…cznie z tego repozytorium.

---

### `report_pdf.py`
- Generator raportu PDF (ReportLab).
- `generate_report_pdf(db_path, job_id, out_path, bucket_seconds)`:
  - pobiera dane z tabel `*_summary`
  - generuje raport PDF:
    - strona tytuÅ‚owa
    - podsumowanie testu
    - statystyki per endpoint
    - analiza trendu w czasie
- ObsÅ‚uguje UTFâ€‘8 (polskie znaki) przez fonty DejaVu.

---

### `rabbit_worker.py`
- Worker integracyjny z RabbitMQ (tryb produkcyjny).
- Subskrybuje dwie kolejki:

**`perf.raw`**
- przyjmuje **pojedynczy DTO lub listÄ™ DTO**
- zapisuje dane RAW do bazy (`insert_raw_result`)

**`perf.ctrl`**
- odbiera komendÄ™ `{"cmd": "job_end", "job_id": X}`
- publikuje komunikat gotowoÅ›ci na `perf.ready`

Worker **nie generuje PDF** â€“ tylko synchronizuje dane.

---

### `sample_request_results.json`
- PrzykÅ‚adowe dane testowe (lista eventÃ³w requestÃ³w).
- UÅ¼ywane przez `main.py` do testÃ³w lokalnych.

---

### `report.pdf`
- PrzykÅ‚adowy wygenerowany raport (artefakt testowy).

---

### `requirements.txt`
Minimalne zaleÅ¼noÅ›ci:
```
reportlab
pika   # tylko jeÅ›li uÅ¼ywany RabbitMQ
```

---

## ğŸ”„ PrzepÅ‚yw danych (highâ€‘level)

1. Backend / testy â†’ wysyÅ‚ajÄ… dane RAW
2. `storage.py` zapisuje RAW do SQLite
3. Po zakoÅ„czeniu joba â†’ `compute_aggregates`
4. Agregaty zapisane w `*_summary`
5. `report_pdf.py` generuje PDF na podstawie agregatÃ³w

---

## â„¹ï¸ Uwagi integracyjne

- ModuÅ‚ **nie wymaga zmian**, jeÅ›li backend dostarcza dane w uzgodnionym DTO.
- RabbitMQ jest opcjonalny â€“ caÅ‚y pipeline dziaÅ‚a lokalnie.
- Projekt celowo rozdziela:
  - RAW data
  - agregacjÄ™
  - raportowanie
  - komunikacjÄ™

DziÄ™ki temu Å‚atwo go podÅ‚Ä…czyÄ‡ do reszty systemu.

